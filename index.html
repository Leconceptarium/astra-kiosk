
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Astra</title>
</head>
<body style="background-color:#000; margin:0; overflow:hidden;">
<script>
  const credentials = {
    project_id: "ia-morpheus",
    token_uri: "https://oauth2.googleapis.com/token"
    // ⚠️ On ne met PAS les clés privées ici : version test uniquement
  };

  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = false;
  recognition.lang = 'fr-FR';

  function detectLang(text) {
    const hasGerman = /[ßäöü]/i.test(text);
    const hasEnglish = /\b(the|you|hello|hi|what|is|are)\b/i.test(text);
    if (hasGerman) return 'de-DE';
    if (hasEnglish) return 'en-US';
    return 'fr-FR';
  }

  function speak(text) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = recognition.lang;
    speechSynthesis.speak(utterance);
  }

  function mockDialogflow(text) {
    const lower = text.toLowerCase();
    if (lower.includes("bonjour") || lower.includes("hello") || lower.includes("guten")) {
      speak("Bonjour Monsieur Morpheus ! Veuillez me donner votre mot de passe.");
    } else if (lower.includes("bonne nuit")) {
      speak("Mot de passe confirmé. Bienvenue dans l’atelier.");
    } else {
      speak("Je ne comprends pas, pouvez-vous répéter ?");
    }
  }

  recognition.onresult = (event) => {
    const text = event.results[event.results.length - 1][0].transcript.trim();
    recognition.lang = detectLang(text);
    console.log("✨ Langue détectée :", recognition.lang, "Texte :", text);
    mockDialogflow(text); // version test (hors connexion à Dialogflow réel)
  };

  recognition.onerror = (event) => {
    console.error("Erreur vocale :", event.error);
  };

  recognition.onend = () => {
    recognition.start();
  };

  recognition.start();
</script>
</body>
</html>
